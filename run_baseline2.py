# -*- coding: utf-8 -*-
"""run_baseline2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l-39vUwo1YR1edVH6yBA_rt0X8jOs6ty
"""

import re
import time
from common import (
    target_df, essay_col, score_col, id_col,
    call_llm, save_results, PROVIDER
)

# è¯¦ç»†çš„åˆ†ç»´åº¦ Rubric
MTS_RUBRIC_DETAILED = """
TRAIT 1: DEVELOPMENT (Ideas, Evidence, Critical Thinking)
- Score 6: Insightfully develops a point of view; outstanding critical thinking.
- Score 1: No viable point of view; little evidence.

TRAIT 2: ORGANIZATION (Structure, Coherence)
- Score 6: Well organized, clear focus, smooth progression.
- Score 1: Disorganized, disjointed.

TRAIT 3: LANGUAGE (Vocabulary, Grammar)
- Score 6: Skillful language, varied vocabulary, few errors.
- Score 1: Pervasive errors, severe flaws.
"""

def run():
    print(f"\nðŸš€ Starting Baseline 2 (MTS Full Context, {len(target_df)} essays)...")
    results = []

    for idx, row in target_df.iterrows():
        # ðŸ”¥ Prompt: å®Œæ•´ä½œæ–‡ï¼Œæ— æˆªæ–­
        prompt = f"""System: Expert MTS Scorer.

### RUBRIC
{MTS_RUBRIC_DETAILED}

### TARGET ESSAY
{row[essay_col]}

### TASK
Score 3 traits independently (1-6). Format EXACTLY as:
Development: [Score]
Organization: [Score]
Language: [Score]
"""

        start_t = time.time()
        raw_out, in_tok = call_llm(prompt, max_tokens=300)
        latency = time.time() - start_t

        try:
            m_d = re.search(r"Development:\s*(\d+)", raw_out, re.I)
            d = int(m_d.group(1)) if m_d else 3
            m_o = re.search(r"Organization:\s*(\d+)", raw_out, re.I)
            o = int(m_o.group(1)) if m_o else 3
            m_l = re.search(r"Language:\s*(\d+)", raw_out, re.I)
            l = int(m_l.group(1)) if m_l else 3
            final = int(round((d+o+l)/3 + 0.001))
            scores = {'d':d, 'o':o, 'l':l}
        except:
            final = None
            scores = {'d':None, 'o':None, 'l':None}

        results.append({
            'essay_id': row[id_col], 'human_score': row[score_col], 'pred_score': final,
            'score_dev': scores['d'], 'score_org': scores['o'], 'score_lang': scores['l'],
            'input_tokens': in_tok, 'latency': round(latency, 2), 'raw_output': raw_out
        })

        if (idx+1) % 10 == 0: print(f"Processed {idx+1}/{len(target_df)}...")
        if PROVIDER != "MOCK": time.sleep(1)

    save_results(results, "Baseline2_MTS_FullContext")

if __name__ == "__main__":
    run()